{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect(database=\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ja_ginza_electra\"\n",
    "db = pd.read_csv(f\"../data/ted_npvs_{model_name}.csv\")\n",
    "db = pd.concat([db, pd.read_csv(f\"../data/jnlp_npvs_{model_name}.csv\")])\n",
    "# NPV＋コーパスごとに集計したいので，Pandasのvalue_counts()を利用し，その結果 (Seriesオブジェクト) をDataFrameに戻す\n",
    "db = db.value_counts().to_frame(name=\"frequency\").reset_index()\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパス間の頻度が比べるために一番小さいコーパスのNPVの数で正規化する\n",
    "corpus_freqs: dict[str, int] = {\n",
    "    corpus: db[db.corpus == corpus][\"frequency\"].sum() for corpus in db.corpus.unique()\n",
    "}\n",
    "min_count = min(corpus_freqs.values())\n",
    "min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_norm = {\n",
    "    corpus: min_count / frequency for corpus, frequency in corpus_freqs.items()\n",
    "}\n",
    "\n",
    "print(corpus_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[\"norm_frequency\"] = db.apply(\n",
    "    lambda r: r[\"frequency\"] * corpus_norm[r[\"corpus\"]], axis=1\n",
    ")\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[db.n == \"変化\"].drop(columns=[\"n\"]).to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "SELECT * FROM db\n",
    "WHERE n = ?\n",
    "GROUP BY p, n, v, corpus, frequency, norm_frequency\n",
    "ORDER BY p, norm_frequency DESC, n\n",
    "\"\"\",\n",
    "    [\"変化\"],\n",
    ").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各種の共起尺度の計算：\n",
    "-   [Relational cooccurrences and contingency tables](http://collocations.de/AM/index.html)\n",
    "\n",
    "\n",
    "共起尺度を計算するには，contingency tableの作成が必要です。\n",
    "\n",
    "単語（共起）ペア$(u,v)$において\n",
    "\n",
    "期待値（Expected frequencies）:\n",
    "\n",
    "|       |$V = v$|$V \\ne v$|\n",
    "|:-----:|:-----:|:-------:|\n",
    "|$U = u$  |$E_{11} = \\frac{R_1 C_1}{N}$|$E_{12} = \\frac{R_1 C_2}{N}$|\n",
    "|$U \\ne u$|$E_{21} = \\frac{R_2 C_1}{N}$|$E_{22} = \\frac{R_2 C_2}{N}$|\n",
    "\n",
    "\n",
    "実現値（Observed frequencies）:\n",
    "\n",
    "|       |$V = v$|$V \\ne v$|   |\n",
    "|:-----:|:-----:|:-------:|:-:|\n",
    "|$U = u$  |$O_{11}$|$O_{12}$|$=R_1$|\n",
    "|$U \\ne u$|$O_{21}$|$O_{22}$|$=R_2$|\n",
    "|         |$C_1$|$C_2$|$=N$|\n",
    "\n",
    "ここは$N$はコーパス全体の共起の延べ数で，$R_1$は$u$の延べ数$R_2$は$u$以外の単語の延べ数，$C_1$は$v$の延べ数$C_2$は$v$以外の単語の延べ数になっている。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
